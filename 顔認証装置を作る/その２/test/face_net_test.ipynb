{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要なライブラリの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIモデルの宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顔検出のAI\n",
    "# image_size: 顔を検出して切り取るサイズ\n",
    "# margin: 顔まわりの余白\n",
    "mtcnn = MTCNN(image_size=160, margin=10)\n",
    "\n",
    "# 切り取った顔を512個の数字にするAI\n",
    "# 1回目の実行では学習済みのモデルをダウンロードしますので、少し時間かかります。\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3つの画像を512個の数値化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "# 三人分の比較をします。\n",
    "# 1つ目をカメラで取得した人として\n",
    "# 2、3つ目を登録されている人とします。\n",
    "image_path1 = \"images/abe.jpg\"\n",
    "image_path2 = \"images/rekidai-index-97-abe.jpg\"\n",
    "image_path3 = \"images/suga1jpeg\"\n",
    "\n",
    "# (仮)カメラで取得した方\n",
    "# 画像データ取得\n",
    "img1 = Image.open(image_path1) \n",
    "# 顔データを160×160に切り抜き\n",
    "img_cropped1 = mtcnn(img1)\n",
    "print(type(img_cropped1))\n",
    "print(img_cropped1.shape)\n",
    "# save_pathを指定すると、切り取った顔画像が確認できます。\n",
    "# img_cropped1 = mtcnn(img1, save_path=\"cropped_img1.jpg\")\n",
    "# 切り抜いた顔データを512個の数字に\n",
    "img_embedding1 = resnet(img_cropped1.unsqueeze(0))\n",
    "# (仮)登録されたカメラと同じ人\n",
    "img2 = Image.open(image_path2)\n",
    "img_cropped2 = mtcnn(img2)\n",
    "img_embedding2 = resnet(img_cropped2.unsqueeze(0))\n",
    "\n",
    "# (仮)登録されたカメラと違う人\n",
    "img3 = Image.open(image_path3)\n",
    "img_cropped3 = mtcnn(img3)\n",
    "img_embedding3 = resnet(img_cropped3.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 類似度計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1つ目と2つ目の比較 0.9331523\n",
      "1つ目と3つ目の比較 0.39355293\n"
     ]
    }
   ],
   "source": [
    "# 類似度の関数\n",
    "def cos_similarity(p1, p2):\n",
    "    return np.dot(p1, p2) / (np.linalg.norm(p1) * np.linalg.norm(p2))\n",
    "\n",
    "# 512個の数字にしたものはpytorchのtensorという型なので、numpyの方に変換\n",
    "# squeeze(): サイズ1の次元を削除\n",
    "p1 = img_embedding1.squeeze().to('cpu').detach().numpy().copy()\n",
    "p2 = img_embedding2.squeeze().to('cpu').detach().numpy().copy()\n",
    "p3 = img_embedding3.squeeze().to('cpu').detach().numpy().copy()\n",
    "\n",
    "# 類似度を計算して顔認証\n",
    "img1vs2 = cos_similarity(p1, p2)\n",
    "img1vs3 = cos_similarity(p1, p3)\n",
    "\n",
    "print(\"1つ目と2つ目の比較\", img1vs2)\n",
    "print(\"1つ目と3つ目の比較\", img1vs3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
